{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9f6811-5ed0-463d-b26b-c83bc16b5d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pgvector in c:\\python311\\lib\\site-packages (0.2.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from pgvector) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\python311\\lib\\site-packages (0.1.32)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
      "                                              0.0/269.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 269.1/269.1 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain-mistralai in c:\\python311\\lib\\site-packages (0.0.5)\n",
      "Collecting langchain-mistralai\n",
      "  Downloading langchain_mistralai-0.1.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python311\\lib\\site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\python311\\lib\\site-packages (from langchain-core) (3.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python311\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\python311\\lib\\site-packages (from langchain-core) (0.1.25)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\python311\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python311\\lib\\site-packages (from langchain-core) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python311\\lib\\site-packages (from langchain-core) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python311\\lib\\site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in c:\\python311\\lib\\site-packages (from langchain-mistralai) (0.25.2)\n",
      "Collecting httpx-sse<1,>=0.3.1 (from langchain-mistralai)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in c:\\python311\\lib\\site-packages (from langchain-mistralai) (0.15.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python311\\lib\\site-packages (from anyio<5,>=3->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python311\\lib\\site-packages (from httpx<1,>=0.25.2->langchain-mistralai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain-mistralai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain-core) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain-core) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests<3,>=2->langchain-core) (2.0.4)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\python311\\lib\\site-packages (from tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (0.21.4)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (2024.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->langchain-mistralai) (0.4.6)\n",
      "Installing collected packages: httpx-sse, langchain-core, langchain-mistralai\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.32\n",
      "    Uninstalling langchain-core-0.1.32:\n",
      "      Successfully uninstalled langchain-core-0.1.32\n",
      "  Attempting uninstall: langchain-mistralai\n",
      "    Found existing installation: langchain-mistralai 0.0.5\n",
      "    Uninstalling langchain-mistralai-0.0.5:\n",
      "      Successfully uninstalled langchain-mistralai-0.0.5\n",
      "Successfully installed httpx-sse-0.4.0 langchain-core-0.1.33 langchain-mistralai-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (0.2.56)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from llama-cpp-python) (4.10.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from llama-cpp-python) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rocky\\appdata\\roaming\\python\\python311\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ./llama-cpp-python is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pgvector\n",
    "%pip install -U langchain-core langchain-mistralai\n",
    "%pip install llama-cpp-python\n",
    "%pip install --upgrade --quiet  flashrank\n",
    "\n",
    "!python -m pip install -e ./llama-cpp-python --force-reinstall --no-cache-dir --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9560963c-ddc1-4974-be95-1425319616e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 3060\n",
      "Using PyTorch version: 2.2.1+cu118\n",
      "Using CUDA version: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError(\"CUDA is not available. Please check your NVIDIA GPU and driver installation.\")\n",
    "print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Step 2: Verify PyTorch and CUDA compatibility\n",
    "print(f\"Using PyTorch version: {torch.__version__}\")\n",
    "print(f\"Using CUDA version: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726686dc-d155-443c-bb3c-b20cfaee79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d3c84e-ebb1-479d-9294-33cbcc01db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"data/\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c9c150-1008-4740-a156-a287e77e28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=100, length_function = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c84fdb4-bd13-4f4a-8a68-ba67cd078336",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "result = []\n",
    "count = 0\n",
    "while (count < len(docs)):\n",
    "    if docs[count].page_content is not None:\n",
    "        docs[count].page_content = docs[count].page_content.replace('\\x00', '')\n",
    "        result.append(docs[count])\n",
    "    count = count + 1\n",
    "docs = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2f64fc-f33a-4ad1-983e-87b37897fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cad98d8-bdb1-4431-bb13-7f4285d4bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/e5-base-v2\")\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#model = SentenceTransformer(\"intfloat/e5-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c1d6fd7-f597-4490-8e61-53c9fc80df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.pgvector import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e02b628c-938d-4ee0-a68b-29bbf9943ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:hello@localhost:5433/vector_db\"\n",
    "\n",
    "COLLECTION_NAME = \"state_of_the_union_test\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2}, search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7acc749c-e252-4337-86f1-0849a8bfbcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Score:  0.2182346712490706\n",
      "THTHE E BEBEGIGINNINGNNING\n",
      "Let the conversation begin…Let the conversation begin…\n",
      "Follow the PenguinFollow the Penguin Twitter.com@penguinbooks Twitter.com@penguinbooks\n",
      "Keep up-to-date with all our storiesKeep up-to-date with all our stories YouTube.com/pen guinbooks YouTube.com/penguinbooks\n",
      "Pin ‘Penguin Books’ to yourPin ‘Penguin Books’ to your Pinterest Pinterest\n",
      "Like ‘Penguin Books’ onLike ‘Penguin Books’ on Facebook.com/penguinbooks Facebook.com/penguinbooks\n",
      "Fi Find out more nd out more abo about the author andut the author and\n",
      "discover more stories like this atdiscover more stories like this at Penguin.co.uk Penguin.co.uk\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.2182346712490706\n",
      "THTHE E BEBEGIGINNINGNNING\n",
      "Let the conversation begin…Let the conversation begin…\n",
      "Follow the PenguinFollow the Penguin Twitter.com@penguinbooks Twitter.com@penguinbooks\n",
      "Keep up-to-date with all our storiesKeep up-to-date with all our stories YouTube.com/pen guinbooks YouTube.com/penguinbooks\n",
      "Pin ‘Penguin Books’ to yourPin ‘Penguin Books’ to your Pinterest Pinterest\n",
      "Like ‘Penguin Books’ onLike ‘Penguin Books’ on Facebook.com/penguinbooks Facebook.com/penguinbooks\n",
      "Fi Find out more nd out more abo about the author andut the author and\n",
      "discover more stories like this atdiscover more stories like this at Penguin.co.uk Penguin.co.uk\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.2182346712490706\n",
      "THTHE E BEBEGIGINNINGNNING\n",
      "Let the conversation begin…Let the conversation begin…\n",
      "Follow the PenguinFollow the Penguin Twitter.com@penguinbooks Twitter.com@penguinbooks\n",
      "Keep up-to-date with all our storiesKeep up-to-date with all our stories YouTube.com/pen guinbooks YouTube.com/penguinbooks\n",
      "Pin ‘Penguin Books’ to yourPin ‘Penguin Books’ to your Pinterest Pinterest\n",
      "Like ‘Penguin Books’ onLike ‘Penguin Books’ on Facebook.com/penguinbooks Facebook.com/penguinbooks\n",
      "Fi Find out more nd out more abo about the author andut the author and\n",
      "discover more stories like this atdiscover more stories like this at Penguin.co.uk Penguin.co.uk\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Score:  0.2182346712490706\n",
      "THTHE E BEBEGIGINNINGNNING\n",
      "Let the conversation begin…Let the conversation begin…\n",
      "Follow the PenguinFollow the Penguin Twitter.com@penguinbooks Twitter.com@penguinbooks\n",
      "Keep up-to-date with all our storiesKeep up-to-date with all our stories YouTube.com/pen guinbooks YouTube.com/penguinbooks\n",
      "Pin ‘Penguin Books’ to yourPin ‘Penguin Books’ to your Pinterest Pinterest\n",
      "Like ‘Penguin Books’ onLike ‘Penguin Books’ on Facebook.com/penguinbooks Facebook.com/penguinbooks\n",
      "Fi Find out more nd out more abo about the author andut the author and\n",
      "discover more stories like this atdiscover more stories like this at Penguin.co.uk Penguin.co.uk\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"PGVECTOR_VECTOR_SIZE\"] = str(768)\n",
    "query = \"your query here\"\n",
    "docs_with_score = db.similarity_search_with_score(query)\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dee8881b-a8b3-4482-840e-f2eef3d5d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "# Load the model, here we use our base sized model\n",
    "compressor = FlashrankRerank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2d4a232-3992-4374-9923-32e5f9bc7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05431267-65a1-4ca1-9a65-b0570c764e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0c960e6-1bdb-4ecc-9475-aaf335b182bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Model\n",
    "#llm = LlamaCpp(\n",
    "   # streaming = True,\n",
    "   # model_path=\"./models/mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "   # n_ctx= 2048,\n",
    "   # verbose=True,\n",
    "   # use_mlock=True,\n",
    "#    n_gpu_layers=12,\n",
    "  #  n_threads=4,\n",
    " #   n_batch=1000\n",
    "#)\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff8cc4a-d3de-46a3-ac99-81874dc0ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=compression_retriever,\n",
    "                                 verbose=True,\n",
    "                                return_source_documents=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ac152-7a9a-435f-9ca7-d37747b96a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QNA():\n",
    "    question = input()\n",
    "    \n",
    "    if question:\n",
    "        # Lets get the scores\n",
    "\n",
    "        print(qa.invoke(question))\n",
    "        QNA()\n",
    "        \n",
    "\n",
    "\n",
    "QNA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e775e6-109d-40b3-a3aa-22799231b981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d817516-158a-4210-8658-7956272a0b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7bfd24-23dd-4ba1-8bf2-931f07e8c4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84589f7c-2815-41e5-844b-838139c49e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba6a84-9f20-4562-931b-78b302790164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea818d08-b588-40e0-b1cf-14beeedce19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb628de2-fae4-4ddb-aa24-6b2be47e6c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54c68f-69a6-4ce5-907c-a30ae8c9e6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
